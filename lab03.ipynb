{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fo942LMOdlh4"
   },
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DokFOdD1dJEl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torch.backends import cudnn\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpeiro98\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/peiro98/aml-lab03/runs/2balbb0u\" target=\"_blank\">aml-lab03</a></strong> to <a href=\"https://wandb.ai/peiro98/aml-lab03\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/peiro98/aml-lab03/runs/2balbb0u?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f09776821c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"aml-lab03\", entity=\"peiro98\", name=\"aml-lab03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIDLJuIXK_vh"
   },
   "source": [
    "**Set Arguments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "d5PkYfqfK_SA"
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # 'cuda' or 'cpu'\n",
    "\n",
    "# available classes: \"dog\", \"elephant\", \"giraffe\", \"guitar\", \"horse\", \"house\", \"person\"\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "LR = 5e-4\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 5e-5\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "STEP_SIZE = 10\n",
    "GAMMA = 0.1\n",
    "\n",
    "LOG_FREQUENCY = 10\n",
    "TRAIN_RATIO = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gwii0TBHvzh"
   },
   "source": [
    "**Define Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QUDdw4j2H0Mc"
   },
   "outputs": [],
   "source": [
    "# Define transforms for training phase\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        # 227x227 -> 224x224\n",
    "        transforms.CenterCrop(224),\n",
    "        # convert to tensor\n",
    "        transforms.ToTensor(),\n",
    "        # normalizes tensor with mean and standard deviation\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define transforms for the evaluation phase\n",
    "eval_transform = train_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qYIHPzYLY7i"
   },
   "source": [
    "### Dataset loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "QfVq_uDHLbsR",
    "outputId": "af2136aa-db20-43e9-8d77-502a323b9484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SRC] train size: 1670\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"PACS/data\"\n",
    "SRC_DATA_DIR = f\"{DATA_DIR}/photo/\"\n",
    "\n",
    "from PACS.PACS import PACSDataset\n",
    "\n",
    "# Prepare Pytorch train/test Datasets\n",
    "src_dataset = PACSDataset(SRC_DATA_DIR, transform=train_transform)\n",
    "\n",
    "# take the indicies corresponding to train samples\n",
    "src_train_indices = np.random.choice(len(src_dataset), size=int(1.0 * len(src_dataset)))\n",
    "# src_val_indices = np.setdiff1d(np.arange(len(src_dataset)), src_train_indices)\n",
    "\n",
    "src_train_dataset = Subset(src_dataset, src_train_indices)\n",
    "# src_validation_dataset = Subset(src_dataset, src_val_indices)\n",
    "\n",
    "print(\"[SRC] train size:\", len(src_train_dataset))\n",
    "# print(\"[SRC] validation size:\", len(src_validation_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TARGET] train size: 1536\n",
      "[TARGET] validation size: 972\n"
     ]
    }
   ],
   "source": [
    "TARGET_DATA_DIR = f\"{DATA_DIR}/art_painting/\"\n",
    "\n",
    "# Prepare Pytorch train/test Datasets\n",
    "target_dataset = PACSDataset(TARGET_DATA_DIR, transform=train_transform)\n",
    "\n",
    "# take the indicies corresponding to train samples\n",
    "target_train_indices = np.random.choice(\n",
    "    len(target_dataset), size=int(TRAIN_RATIO * len(target_dataset))\n",
    ")\n",
    "target_val_indices = np.setdiff1d(np.arange(len(target_dataset)), target_train_indices)\n",
    "\n",
    "target_train_dataset = Subset(target_dataset, target_train_indices)\n",
    "target_validation_dataset = Subset(target_dataset, target_val_indices)\n",
    "\n",
    "print(\"[TARGET] train size:\", len(target_train_dataset))\n",
    "print(\"[TARGET] validation size:\", len(target_validation_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYEDQ7Z21ldN"
   },
   "source": [
    "**Prepare Dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VriRw8SI1nle"
   },
   "outputs": [],
   "source": [
    "# Train dataloaders\n",
    "src_dataloader = DataLoader(\n",
    "    src_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True\n",
    ")\n",
    "# src_train_dataloader = DataLoader(src_train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
    "# target_train_dataloader = DataLoader(target_train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "# Validation dataloaders\n",
    "target_dataloader = DataLoader(\n",
    "    target_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=True\n",
    ")\n",
    "# src_validation_dataloader = DataLoader(src_validation_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=True)\n",
    "# target_validation_dataloader = DataLoader(target_validation_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbZ1t5Qs2z4j"
   },
   "source": [
    "**Prepare Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "exHUjtXa22DN"
   },
   "outputs": [],
   "source": [
    "from DANN import build_model as build_DANN\n",
    "\n",
    "DANN = build_DANN(7, 2, True)  # n. of classes, n. of domains, pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEyL3H_R4qCf"
   },
   "source": [
    "**Prepare Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9sjq00G94tSc"
   },
   "outputs": [],
   "source": [
    "# classification => cross entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "    DANN.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxYUli9d9uYQ"
   },
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZcoQ5fD49yT_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 1.96 GiB total capacity; 1.07 GiB already allocated; 44.88 MiB free; 1.16 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_70470/1950701967.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Compute gradients for each layer and update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# backward pass: computes gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# update weights based on accumulated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/py-venv/lib64/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/py-venv/lib64/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;32m~/dev/py-venv/lib64/python3.9/site-packages/wandb/wandb_torch.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(grad)\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_tensor_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_track\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hook_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/py-venv/lib64/python3.9/site-packages/wandb/wandb_torch.py\u001b[0m in \u001b[0;36m_callback\u001b[0;34m(grad, log_track)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlog_track_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_track\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_tensor_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_track\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/py-venv/lib64/python3.9/site-packages/wandb/wandb_torch.py\u001b[0m in \u001b[0;36mlog_tensor_stats\u001b[0;34m(self, tensor, name)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# Remove nans from tensor. There's no good way to represent that in histograms.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mflat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0mflat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 1.96 GiB total capacity; 1.07 GiB already allocated; 44.88 MiB free; 1.16 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# By default, everything is loaded to cpu\n",
    "DANN = DANN.to(DEVICE)  # this will bring the network to GPU if DEVICE is cuda\n",
    "wandb.watch(DANN, log_freq=10)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "current_step = 0\n",
    "# Start iterating over the epochs\n",
    "for epoch in tqdm(range(10)):\n",
    "    # print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_last_lr()))\n",
    "\n",
    "    # Iterate over the dataset\n",
    "    for images, labels in src_dataloader:\n",
    "        # Bring data over the device of choice\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        DANN.train()  # Sets module in training mode\n",
    "\n",
    "        optimizer.zero_grad()  # Zero-ing the gradients\n",
    "        outputs = DANN(images)\n",
    "\n",
    "        # Compute loss based on output and ground truth\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Log loss\n",
    "        # if current_step % LOG_FREQUENCY == 0:\n",
    "        #  print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
    "\n",
    "        # Compute gradients for each layer and update weights\n",
    "        loss.backward()  # backward pass: computes gradients\n",
    "        optimizer.step()  # update weights based on accumulated gradients\n",
    "\n",
    "        current_step += 1\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsHFI-GAJd69"
   },
   "source": [
    "**Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "EO3HV5pqJg1o"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:05<00:00, 16.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8237347294938918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DANN.train(False)  # Set Network to evaluation mode\n",
    "\n",
    "running_corrects = 0\n",
    "for images, labels in tqdm(target_dataloader):\n",
    "    images = images.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "\n",
    "    # Forward Pass\n",
    "    outputs = DANN(images)\n",
    "\n",
    "    # Get predictions\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "    # Update Corrects\n",
    "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = running_corrects / float(len(target_dataset))\n",
    "\n",
    "print(\"Validation Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxekmR745ySe"
   },
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fSHcUqLB5yWO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:05<00:00, 17.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8354649153128241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = net.to(DEVICE)  # this will bring the network to GPU if DEVICE is cuda\n",
    "net.train(False)  # Set Network to evaluation mode\n",
    "\n",
    "running_corrects = 0\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "    images = images.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "\n",
    "    # Forward Pass\n",
    "    outputs = net(images)\n",
    "\n",
    "    # Get predictions\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "    # Update Corrects\n",
    "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = running_corrects / float(len(test_dataset))\n",
    "\n",
    "print(\"Test Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Homework2-MLDL.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "54126dcf83d3b19f1df3b8c2eeabae9ee231726106b34df49b0e6acbb809dc7f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('py-venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
